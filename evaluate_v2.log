/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(

Evaluating with Risk Level: Safe (0)
Traceback (most recent call last):
  File "/home/tristan/CodingProjects/ai_pokemon/evaluate_risk.py", line 77, in <module>
    evaluate("models/ppo_risk_agent")
    ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/evaluate_risk.py", line 56, in evaluate
    battle = pz_env.agent1.current_battle
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: '_EnvPlayer' object has no attribute 'current_battle'

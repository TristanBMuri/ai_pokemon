/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
Observation Space Type: <class 'gymnasium.spaces.box.Box'>
Observation Space: Box(0.0, 1.0, (5,), float32)
Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Starting training...
Logging to tmp/battler/PPO_3
Training finished!
Traceback (most recent call last):
  File "/home/tristan/CodingProjects/ai_pokemon/nuzlocke_gauntlet_rl/envs/battle_env.py", line 113, in action_to_order
    return super().action_to_order(action, battle, fake=fake, strict=strict)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/poke_env/environment/singles_env.py", line 166, in action_to_order
    raise e
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/poke_env/environment/singles_env.py", line 123, in action_to_order
    assert order.order.base_species in [
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        p.base_species for p in battle.available_switches
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ], "invalid action"
    ^
AssertionError: invalid action

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/tristan/CodingProjects/ai_pokemon/train_battler.py", line 63, in <module>
    train()
    ~~~~~^^
  File "/home/tristan/CodingProjects/ai_pokemon/train_battler.py", line 54, in train
    model.learn(total_timesteps=10000)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ~~~~~~~~~~~~~^
        total_timesteps=total_timesteps,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        progress_bar=progress_bar,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
           ~~~~~~~~~~~~~~^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
                                                                                  ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.actions[env_idx]
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ~~~~~~~~~~~~~^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/poke_env/environment/single_agent_wrapper.py", line 29, in step
    obs, rewards, terms, truncs, infos = self.env.step(actions)
                                         ~~~~~~~~~~~~~^^^^^^^^^
  File "/home/tristan/CodingProjects/ai_pokemon/.venv/lib/python3.13/site-packages/poke_env/environment/env.py", line 252, in step
    order1 = self.action_to_order(
        actions[self.agents[0]],
    ...<2 lines>...
        strict=self.strict,
    )
  File "/home/tristan/CodingProjects/ai_pokemon/nuzlocke_gauntlet_rl/envs/battle_env.py", line 117, in action_to_order
    return self.choose_random_move(battle)
           ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BattleEnv' object has no attribute 'choose_random_move'
